import os
import re
import time
import random
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from bs4 import BeautifulSoup
import html2text

def process_zhihu(collection_id, only_title_link=True, from_page=None, to_page=None):
    """
    çŸ¥ä¹æ”¶è—å¤¹ä¸‹è½½å·¥å…·
    
    å‚æ•°:
    collection_id: æ”¶è—å¤¹ID (å­—ç¬¦ä¸²)
    only_title_link: æ˜¯å¦åªæŠ“å–æ ‡é¢˜å’Œé“¾æ¥ (å¸ƒå°”å€¼ï¼Œé»˜è®¤ä¸ºTrue)
    from_page: èµ·å§‹é¡µç  (æ•´æ•°ï¼Œå¯é€‰)
    to_page: ç»“æŸé¡µç  (æ•´æ•°ï¼Œå¯é€‰)
    """
    # é…ç½®ä¿¡æ¯
    ZHIHU_USERNAME = ""
    ZHIHU_PASSWORD = ""
    BASE_URL = f"https://www.zhihu.com/collection/{collection_id}"
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å
    output_suffix = "æ ‡é¢˜å’Œé“¾æ¥" if only_title_link else "å®Œæ•´å†…å®¹"
    
    # ç¡®å®šé¡µç èŒƒå›´æè¿°
    if from_page is not None and to_page is not None:
        page_range = f"_{from_page}-{to_page}é¡µ"
        page_range_desc = f"ä»ç¬¬{from_page}é¡µåˆ°ç¬¬{to_page}é¡µ"
    elif from_page is not None:
        page_range = f"_ä»{from_page}é¡µå¼€å§‹"
        page_range_desc = f"ä»ç¬¬{from_page}é¡µå¼€å§‹"
        to_page = from_page  # åªæŠ“å–ä¸€é¡µ
    elif to_page is not None:
        page_range = f"_åˆ°{to_page}é¡µ"
        page_range_desc = f"åˆ°ç¬¬{to_page}é¡µç»“æŸ"
        from_page = 1  # ä»ç¬¬ä¸€é¡µå¼€å§‹
    else:
        page_range = "_å…¨é‡"
        page_range_desc = "æ‰€æœ‰é¡µé¢"
        from_page = 1
        to_page = 1000  # è®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„æ•°
    
    OUTPUT_FILE = f"çŸ¥ä¹æ”¶è—_{collection_id}{page_range}_{output_suffix}.txt"
    
    def init_driver():
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        chrome_options = Options()
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        return webdriver.Chrome(options=chrome_options)
    
    def login(driver):
        """ç™»å½•çŸ¥ä¹"""
        print("å¯åŠ¨æµè§ˆå™¨ç™»å½•çŸ¥ä¹...")
        driver.maximize_window()
        driver.get("https://www.zhihu.com/signin")
        
        try:
            # åˆ‡æ¢åˆ°å¯†ç ç™»å½•
            WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, '.SignContainer-switch span'))
            ).click()
            time.sleep(1)
        except:
            print("æ— æ³•ç‚¹å‡»ç™»å½•æ–¹å¼åˆ‡æ¢ï¼Œå°è¯•ç»§ç»­")
        
        # è¾“å…¥ç”¨æˆ·å
        username_field = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.NAME, 'username'))
        )
        username_field.clear()
        username_field.send_keys(ZHIHU_USERNAME)
        
        # è¾“å…¥å¯†ç 
        password_field = driver.find_element(By.NAME, 'password')
        password_field.clear()
        password_field.send_keys(ZHIHU_PASSWORD)
        
        # ç‚¹å‡»ç™»å½•
        driver.find_element(By.CSS_SELECTOR, '.SignFlow-submitButton').click()
        
        # ç­‰å¾…ç™»å½•æˆåŠŸ
        try:
            WebDriverWait(driver, 15).until(
                lambda d: "www.zhihu.com" in d.current_url and "signin" not in d.current_url
            )
            print("ç™»å½•æˆåŠŸ!")
            return True
        except:
            print("ç™»å½•å¤±è´¥æˆ–éœ€è¦éªŒè¯ç ")
            return False
    
    def get_page_items(driver, page_num):
        """è·å–æŒ‡å®šé¡µé¢çš„æ”¶è—é¡¹"""
        page_url = f"{BASE_URL}?page={page_num}"
        print(f"è®¿é—®ç¬¬ {page_num} é¡µ: {page_url}")
        driver.get(page_url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".ContentItem"))
            )
            print(f"ç¬¬ {page_num} é¡µåŠ è½½æˆåŠŸ")
        except TimeoutException:
            print(f"ç¬¬ {page_num} é¡µåŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­")
            return []
        except Exception as e:
            print(f"ç¬¬ {page_num} é¡µåŠ è½½å‡ºé”™: {str(e)}")
            return []
        
        # æ»šåŠ¨åŠ è½½å½“å‰é¡µæ‰€æœ‰å†…å®¹
        print("æ»šåŠ¨åŠ è½½é¡µé¢å†…å®¹...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        
        while scroll_attempts < 3:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(0.5, 1.0))
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height:
                scroll_attempts += 1
            else:
                scroll_attempts = 0
                last_height = new_height
        
        # è·å–å½“å‰é¡µæ‰€æœ‰æ”¶è—é¡¹
        try:
            items = driver.find_elements(By.CSS_SELECTOR, ".ContentItem")
            print(f"ç¬¬ {page_num} é¡µæ‰¾åˆ° {len(items)} ä¸ªæ”¶è—é¡¹")
            return items
        except Exception as e:
            print(f"è·å–æ”¶è—é¡¹å¤±è´¥: {str(e)}")
            return []
    
    def extract_title_and_link(item):
        """ä»æ”¶è—é¡¹ä¸­æå–æ ‡é¢˜å’Œé“¾æ¥"""
        try:
            # æå–æ ‡é¢˜å…ƒç´ 
            title_element = item.find_element(By.CSS_SELECTOR, ".ContentItem-title a")
            title = title_element.text.strip()
            link = title_element.get_attribute("href")
            return title, link
        except:
            try:
                # å¤‡é€‰é€‰æ‹©å™¨
                title_element = item.find_element(By.CSS_SELECTOR, ".ContentItem-title")
                title = title_element.text.strip()
                link_element = item.find_element(By.CSS_SELECTOR, ".ContentItem-title a")
                link = link_element.get_attribute("href")
                return title, link
            except Exception as e:
                print(f"æå–æ ‡é¢˜å’Œé“¾æ¥å¤±è´¥: {str(e)}")
                return None, None
    
    def save_title_and_link(output_file, index, title, link):
        """ä¿å­˜æ ‡é¢˜å’Œé“¾æ¥åˆ°æ–‡ä»¶"""
        with open(output_file, "a", encoding="utf-8") as f:
            f.write(f"{index}. {title}\n")
            f.write(f"é“¾æ¥: {link}\n")
            f.write("-" * 80 + "\n")
    
    def extract_text_content(html_content):
        """ä»HTMLä¸­æå–çº¯æ–‡æœ¬å†…å®¹"""
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æå–æ ‡é¢˜
        title = ""
        title_element = soup.find('h1', class_='QuestionHeader-title')
        if not title_element:
            title_element = soup.find('h1', class_='Post-Title')
        if title_element:
            title = title_element.get_text(strip=True)
        
        # æå–æ­£æ–‡
        content_div = soup.find('div', class_='Post-RichTextContainer')
        if not content_div:
            content_div = soup.find('div', class_='QuestionAnswer-content')
        if not content_div:
            content_div = soup.find('div', class_='RichContent')
        
        content_text = ""
        if content_div:
            # ä½¿ç”¨html2textå°†HTMLè½¬æ¢ä¸ºMarkdownæ ¼å¼æ–‡æœ¬
            h = html2text.HTML2Text()
            h.ignore_links = True  # å¿½ç•¥é“¾æ¥
            h.ignore_images = True  # å¿½ç•¥å›¾ç‰‡
            h.ignore_emphasis = True  # å¿½ç•¥æ–œä½“/ç²—ä½“æ ¼å¼
            content_text = h.handle(str(content_div))
        
        return title, content_text
    
    def process_full_content(driver, item, output_file, index):
        """å¤„ç†å•ä¸ªæ”¶è—é¡¹å¹¶æå–å®Œæ•´å†…å®¹"""
        # æå–æ–‡ç« æ ‡é¢˜å’Œé“¾æ¥
        title, link = extract_title_and_link(item)
        if not title or not link:
            print(f"æ— æ³•æå–ç¬¬ {index} é¡¹çš„æ ‡é¢˜å’Œé“¾æ¥")
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"{index}. æ— æ³•æå–æ ‡é¢˜å’Œé“¾æ¥\n")
                f.write("-" * 80 + "\n")
            return
        
        print(f"å¤„ç† ({index}): {title}")
        
        # åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€æ–‡ç« 
        driver.execute_script(f"window.open('{link}');")
        driver.switch_to.window(driver.window_handles[1])
        
        try:
            # ç­‰å¾…æ–‡ç« åŠ è½½
            WebDriverWait(driver, 30).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".Post-Main, .Question-main"))
            )
            
            # è·å–å®Œæ•´çš„HTMLæºç 
            html_content = driver.page_source
            
            # æå–çº¯æ–‡æœ¬å†…å®¹
            article_title, article_content = extract_text_content(html_content)
            
            # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨åŸæ ‡é¢˜
            if not article_title:
                article_title = title
            
            # å†™å…¥è¾“å‡ºæ–‡ä»¶
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"{index}. {article_title}\n")
                f.write(f"é“¾æ¥: {link}\n")
                f.write("-" * 80 + "\n")
                f.write(article_content.strip() + "\n")
                f.write("\n" + "=" * 80 + "\n\n")
            
            print(f"âœ… å·²ä¿å­˜: {article_title}")
            
        except Exception as e:
            print(f"å¤„ç†æ–‡ç« å¤±è´¥: {str(e)}")
            # å¦‚æœæå–å¤±è´¥ï¼Œè‡³å°‘ä¿å­˜æ ‡é¢˜å’Œé“¾æ¥
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"{index}. {title}\n")
                f.write(f"é“¾æ¥: {link}\n")
                f.write(f"é”™è¯¯: æ— æ³•æå–å†…å®¹ ({str(e)})\n")
                f.write("\n" + "=" * 80 + "\n\n")
        finally:
            # å…³é—­æ–‡ç« æ ‡ç­¾é¡µï¼Œåˆ‡å›ä¸»çª—å£
            driver.close()
            driver.switch_to.window(driver.window_handles[0])
            time.sleep(random.uniform(1, 2))  # éšæœºç­‰å¾…æ—¶é—´ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
    
    # ä¸»æ‰§è¡Œé€»è¾‘
    print("="*50)
    print("çŸ¥ä¹æ”¶è—å¤¹ä¸‹è½½å·¥å…·")
    print(f"æ”¶è—å¤¹ID: {collection_id}")
    print(f"æŠ“å–æ¨¡å¼: {'ä»…æ ‡é¢˜å’Œé“¾æ¥' if only_title_link else 'å®Œæ•´å†…å®¹'}")
    print(f"é¡µç èŒƒå›´: {page_range_desc}")
    print(f"è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print("="*50)
    
    # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(f"çŸ¥ä¹æ”¶è—å†…å®¹æ±‡æ€»\n")
        f.write(f"æ”¶è—å¤¹ID: {collection_id}\n")
        f.write(f"æŠ“å–æ¨¡å¼: {'ä»…æ ‡é¢˜å’Œé“¾æ¥' if only_title_link else 'å®Œæ•´å†…å®¹'}\n")
        f.write(f"é¡µç èŒƒå›´: {page_range_desc}\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
    
    # åˆå§‹åŒ–æµè§ˆå™¨
    driver = init_driver()
    total_items = 0  # æ€»é¡¹ç›®è®¡æ•°
    
    try:
        # ç™»å½•
        if not login(driver):
            print("ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ä¸‹è½½")
            return
        
        # ç¡®å®šèµ·å§‹é¡µç å’Œç»“æŸé¡µç 
        start_page = from_page
        end_page = to_page
        
        # éå†æŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰é¡µé¢
        for current_page in range(start_page, end_page + 1):
            print(f"\n===== å¼€å§‹å¤„ç†ç¬¬ {current_page} é¡µ =====")
            
            try:
                # è·å–å½“å‰é¡µæ”¶è—é¡¹
                items = get_page_items(driver, current_page)
                
                # å¤„ç†å½“å‰é¡µæ‰€æœ‰æ”¶è—é¡¹
                for i, item in enumerate(items, 1):
                    index = total_items + i
                    
                    if only_title_link:
                        # ä»…ä¿å­˜æ ‡é¢˜å’Œé“¾æ¥
                        title, link = extract_title_and_link(item)
                        if title and link:
                            print(f"å¤„ç† ({index}): {title}")
                            save_title_and_link(OUTPUT_FILE, index, title, link)
                        else:
                            print(f"æ— æ³•æå–ç¬¬ {index} é¡¹çš„æ ‡é¢˜å’Œé“¾æ¥")
                            with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
                                f.write(f"{index}. æ— æ³•æå–æ ‡é¢˜å’Œé“¾æ¥\n")
                                f.write("-" * 80 + "\n")
                    else:
                        # æŠ“å–å®Œæ•´å†…å®¹
                        process_full_content(driver, item, OUTPUT_FILE, index)
                
                total_items += len(items)
                print(f"===== ç¬¬ {current_page} é¡µå¤„ç†å®Œæˆï¼Œå…± {len(items)} é¡¹ =====")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œç­‰å¾…ä¸€ä¸‹å†å¤„ç†ä¸‹ä¸€é¡µ
                if current_page < end_page:
                    time.sleep(random.uniform(2, 4))
                    
            except Exception as e:
                print(f"å¤„ç†ç¬¬ {current_page} é¡µæ—¶å‡ºé”™: {str(e)}")
                # å°è¯•ä¸‹ä¸€é¡µ
                if current_page < end_page:
                    time.sleep(5)  # å‡ºé”™åç­‰å¾…æ›´é•¿æ—¶é—´
    
    except Exception as e:
        print(f"ä¸»æµç¨‹å‡ºé”™: {str(e)}")
        driver.save_screenshot("main_error.png")
    finally:
        print("å…³é—­æµè§ˆå™¨...")
        driver.quit()
        print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼æ‰€æœ‰å†…å®¹ä¿å­˜åœ¨: {os.path.abspath(OUTPUT_FILE)}")
        print(f"æ€»å…±å¤„ç†äº† {total_items} ä¸ªæ”¶è—é¡¹")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹1ï¼šæŠ“å–å®Œæ•´å†…å®¹ï¼Œç¬¬65é¡µ
    process_zhihu("88652213", only_title_link=False, from_page=1, to_page=10)
    
    # ç¤ºä¾‹2ï¼šåªæŠ“å–æ ‡é¢˜å’Œé“¾æ¥ï¼Œç¬¬65é¡µ
    # process_zhihu("713314943", only_title_link=True, from_page=65, to_page=65)
    
    # ç¤ºä¾‹3ï¼šæŠ“å–å®Œæ•´å†…å®¹ï¼Œç¬¬65é¡µåˆ°ç¬¬70é¡µ
    # process_zhihu("713314943", only_title_link=False, from_page=65, to_page=70)
    
    # ç¤ºä¾‹4ï¼šåªæŠ“å–æ ‡é¢˜å’Œé“¾æ¥ï¼Œç¬¬65é¡µåˆ°ç¬¬70é¡µ
    # process_zhihu("713314943", only_title_link=True, from_page=65, to_page=70)
